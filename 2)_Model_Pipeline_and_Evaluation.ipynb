{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2) Model Pipeline and Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JX53hsQZ3WUc"
      },
      "source": [
        "# Model Pipeline and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuCBHI_gQju8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOZHTS7Qn7j",
        "colab_type": "code",
        "outputId": "3dfe6213-1d3f-4b30-910c-c82817b6604a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "if not local:\n",
        "    !apt-get install openslide-tools\n",
        "    !pip install openslide-python"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 71%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33n1pog9QsOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not local:\n",
        "    %tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7nOLta4Qs33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.patches as mp_patches\n",
        "\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn import metrics\n",
        "from matplotlib import gridspec\n",
        "from matplotlib.colors import Normalize\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZGXDdQ4Q0cK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a396d221-5cc3-4e36-a896-fb551a538407"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akqnThD5Q_wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not local:\n",
        "  folder_root = \"/content/drive/My Drive/4995-final\"\n",
        "  slides_folder = os.path.join(folder_root, 'slides')\n",
        "else:\n",
        "  folder_root = '.'\n",
        "  slides_folder = '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF-8g0lqRBlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(folder_root):\n",
        "  os.mkdir(folder_root)\n",
        "\n",
        "if not os.path.exists(slides_folder):\n",
        "  os.mkdir(slides_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEpRWZ7Olqq_",
        "colab_type": "text"
      },
      "source": [
        "# Slide Related Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15FTYkG9dfq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See https://openslide.org/api/python/#openslide.OpenSlide.read_region\n",
        "# Note: x,y coords are with respect to level 0.\n",
        "# There is an example below of working with coordinates\n",
        "# with respect to a higher zoom level.\n",
        "\n",
        "# Read a region from the slide\n",
        "# Return a numpy RBG array\n",
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "  im = slide.read_region((x,y), level, (width, height))\n",
        "  im = im.convert('RGB') # drop the alpha channel\n",
        "  if as_float:\n",
        "      im = np.asarray(im, dtype=np.float32)\n",
        "  else:\n",
        "      im = np.asarray(im)\n",
        "  assert im.shape == (height, width, 3)\n",
        "  return im\n",
        "\n",
        "# of the slide. We'll find these by looking for all gray regions.\n",
        "def find_tissue_pixels(image, intensity=0.8):\n",
        "    im_gray = rgb2gray(image)\n",
        "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
        "    indices = np.where(im_gray <= intensity)\n",
        "    return list(zip(indices[0], indices[1]))\n",
        "\n",
        "def apply_mask(im, mask, color=(255,0,0)):\n",
        "    masked = np.copy(im)\n",
        "    for x,y in mask: masked[x][y] = color\n",
        "    return masked\n",
        "\n",
        "def create_tissue_mask(im, mask, color=(1,1,1)):\n",
        "    masked = np.zeros(im.shape)\n",
        "    for x,y in mask: masked[x][y] = color\n",
        "    return masked\n",
        "\n",
        "def get_downsample_ratio(level):\n",
        "  return 2**level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "822xXtbktWci",
        "colab_type": "text"
      },
      "source": [
        "# Patch Extraction Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09SUlqN3tU4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_patch_tumor(mask, patch_center):\n",
        "  \"\"\"Check if the patch within patch_center x patch_center contains tumor\n",
        "  \n",
        "  mask: the tumor mask\n",
        "  patch_center: the patch centroid and size\n",
        "  \"\"\"\n",
        "  y = int(round(mask.shape[0]/2)) - int(round(patch_center/2))\n",
        "  x = int(round(mask.shape[1]/2)) - int(round(patch_center/2))\n",
        "  center_region = mask[y:y+patch_center, x:x+patch_center]\n",
        "\n",
        "  return np.sum(center_region) > 0\n",
        "\n",
        "def get_dim_from_slide(slide, lvl):\n",
        "  \"\"\"Get the dimension of a level\n",
        "\n",
        "  slide: a slide image\n",
        "  lvl: a level\n",
        "  \"\"\"\n",
        "  return int(slide.level_downsamples[lvl])\n",
        "\n",
        "def extract_patches_only_from_center(x, y, slide, tumor_mask, lvl, patch_size):\n",
        "  \"\"\"Extract slide and tumor patches.\n",
        "\n",
        "  x: x-axis center\n",
        "  y: y-axis center\n",
        "  slide: the full image slide\n",
        "  tumor_mask: the full tumor mask slide\n",
        "  lvl: zoom level\n",
        "  patch_size: the size of the patch\n",
        "  \"\"\"\n",
        "  dim = get_dim_from_slide(slide, lvl)\n",
        "    \n",
        "  # extract slide image by patch_size x patch_size centered at patch_center x patch_center size\n",
        "  slide_patch = read_slide(\n",
        "    slide, \n",
        "    x=(x - patch_size//2)*dim, \n",
        "    y=(y - patch_size//2)*dim,\n",
        "    level=lvl, \n",
        "    width=patch_size, \n",
        "    height=patch_size\n",
        "  )\n",
        "\n",
        "  # extract tumor by patch_size x patch_size centered at patch_center x patch_center size\n",
        "  tumor_patch = read_slide(\n",
        "      tumor_mask, \n",
        "      x=(x - patch_size//2)*dim, \n",
        "      y=(y - patch_size//2)*dim,\n",
        "      level=lvl, \n",
        "      width=patch_size, \n",
        "      height=patch_size\n",
        "  )\n",
        "\n",
        "  # tumor patch just use one channel\n",
        "  tumor_patch = tumor_patch[:, :, 0]\n",
        "\n",
        "  return slide_patch, tumor_patch\n",
        "\n",
        "def extract_patches_from_center(x, y, slide, tumor_mask, lvl, patch_size):\n",
        "  \"\"\"Extract slide, tumor and tissue regions\n",
        "\n",
        "  x: x-axis center\n",
        "  y: y-axis center\n",
        "  slide: the full image slide\n",
        "  tumor_mask: the full tumor mask slide\n",
        "  lvl: zoom level\n",
        "  patch_size: the size of the patch\n",
        "  \"\"\"\n",
        "  slide_patch, tumor_patch = extract_patches_only_from_center(x, y, slide, \n",
        "                                                              tumor_mask, lvl, patch_size)\n",
        "  \n",
        "  # extract tissue pixels\n",
        "  tissue_pixels = find_tissue_pixels(slide_patch)\n",
        "  percent_tissue = len(tissue_pixels) / float(slide_patch.shape[0] * slide_patch.shape[0]) * 100\n",
        "  \n",
        "  return slide_patch, tumor_patch, tissue_pixels, percent_tissue\n",
        "\n",
        "def extract_patches(slide, tumor_mask, lvl, patch_center=128, patch_size=299, \n",
        "                    max_patches=100, plot_patch=False, healthy_ratio=0.6):\n",
        "  \"\"\"Extract slide and tumor patches and labels to build the training data for a slide\n",
        "\n",
        "  slide: slide for the image\n",
        "  tumor mask: slide for the mask\n",
        "  lvl: zoom level\n",
        "  max_patches: how many patches to extract\n",
        "  plot_patch: boolean to indicate plotting the image\n",
        "  healthy_ratio: the ratio between healthy and tumor patches\n",
        "  \"\"\"\n",
        "  print(\"===Start Extracting patches..===\")\n",
        "  start_time = time.time() / 60\n",
        "  data_patches, data_masks, data_labels, data_tissues = [], [], [], []\n",
        "  \n",
        "  # number of possible patches\n",
        "  dim = int(tumor_mask.level_downsamples[lvl])\n",
        "  \n",
        "  # extract full patch\n",
        "  slide_image = read_slide(\n",
        "    slide, \n",
        "    x=0, \n",
        "    y=0,\n",
        "    level=lvl, \n",
        "    width=slide.level_dimensions[lvl][0], \n",
        "    height=slide.level_dimensions[lvl][1]\n",
        "  )\n",
        "  \n",
        "  # extract tumor patches\n",
        "  tumor_image = read_slide(\n",
        "    tumor_mask, \n",
        "    x=0, \n",
        "    y=0,\n",
        "    level=lvl, \n",
        "    width=tumor_mask.level_dimensions[lvl][0], \n",
        "    height=tumor_mask.level_dimensions[lvl][1]\n",
        "  )\n",
        "  # tumor patch just use one channel\n",
        "  tumor_image = tumor_image[:,:,0]\n",
        "  \n",
        "  # check if it's a tissue pixels\n",
        "  tissue_pixels = find_tissue_pixels(slide_image)\n",
        "  tissue_masked = create_tissue_mask(slide_image, tissue_pixels)\n",
        "\n",
        "  tissue_healthy = tissue_masked[:,:,0] - tumor_image\n",
        "  tissue_healthy[tissue_healthy < 0] = 0\n",
        "  \n",
        "  # extract tumorous patches, returns indexes (arr[y], arr[x])\n",
        "  tissue_tumor_idx = np.where(tumor_image > 0)\n",
        "  \n",
        "  # extract healthy patches, returns indexes (arr[y], arr[x])\n",
        "  tissue_healthy_idx = np.where(tissue_healthy > 0)\n",
        "  \n",
        "  print(\"#tumorous tissue pixels: {}, #healthy tissue pixels: {}\".format(\n",
        "    len(tissue_tumor_idx[0]),\n",
        "    len(tissue_healthy_idx[0]),\n",
        "  ))\n",
        "  \n",
        "  # sample from tumor pixels (x, y)\n",
        "  max_tumor = int(max_patches * (1 - healthy_ratio))\n",
        "  tumor_pixels = random.sample(list(zip(tissue_tumor_idx[1], tissue_tumor_idx[0])), \n",
        "                                min(1000, len(tissue_tumor_idx[0]) // 2))\n",
        "  \n",
        "  # sample from healthy pixels (x, y)\n",
        "  max_healthy = int(max_patches * healthy_ratio)\n",
        "  healthy_pixels = random.sample(list(zip(tissue_healthy_idx[1], tissue_healthy_idx[0])), \n",
        "                                  min(5000, len(tissue_healthy_idx[0]) // 2))\n",
        "  \n",
        "  # extract tumor patches\n",
        "  count_tumor = 0\n",
        "  while len(tumor_pixels) != 0 and count_tumor < max_tumor:\n",
        "    (x, y) = tumor_pixels.pop()\n",
        "      \n",
        "    # extract center patches\n",
        "    slide_patch, tumor_patch, tissue_patch, percent_tissue = \\\n",
        "      extract_patches_from_center(x, y, slide, tumor_mask, lvl, patch_size)\n",
        "      \n",
        "    # add to healthy if it's not a tumor\n",
        "    if percent_tissue > 50 and is_patch_tumor(tumor_patch, patch_center):\n",
        "      data_patches.append(slide_patch)\n",
        "      data_masks.append(tumor_patch)\n",
        "      data_labels.append(1)\n",
        "      \n",
        "      count_tumor += 1\n",
        "  \n",
        "  # extract healthy patches\n",
        "  count_healthy = 0\n",
        "  while len(healthy_pixels) != 0 and count_healthy < max_healthy:\n",
        "    (x, y) = healthy_pixels.pop()\n",
        "    \n",
        "    # extract center patches\n",
        "    slide_patch, tumor_patch, tissue_patch, percent_tissue = \\\n",
        "        extract_patches_from_center(x, y, slide, tumor_mask, lvl, patch_size)\n",
        "\n",
        "    # check if it's a tissue pixels\n",
        "    tissue_pixels = find_tissue_pixels(slide_patch)\n",
        "    percent_tissue = len(tissue_pixels) / float(slide_patch.shape[0] * slide_patch.shape[0]) * 100\n",
        "    \n",
        "    # add to healthy if it's not a tumor\n",
        "    if percent_tissue > 50 and not is_patch_tumor(tumor_patch, patch_center):\n",
        "      data_patches.append(slide_patch)\n",
        "      data_masks.append(tumor_patch)\n",
        "      data_labels.append(0)\n",
        "      \n",
        "      count_healthy += 1\n",
        "  \n",
        "  print(\"Tumor Patches: {}, Healthy Patches: {}\".format(count_tumor, count_healthy))\n",
        "  data_patches, data_masks, data_labels = (\n",
        "    np.array(data_patches), \n",
        "    np.array(data_masks), \n",
        "    np.array(data_labels)\n",
        "  )\n",
        "  extraction_time = time.time()/60 - start_time\n",
        "  \n",
        "  if plot_patch:\n",
        "    # plot images\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(15, 15))\n",
        "    axes[0].imshow(slide_image)\n",
        "    axes[0].set_title(\"full slide\")\n",
        "\n",
        "    axes[1].imshow(tumor_image)\n",
        "    axes[1].set_title(\"full tumor mask\")\n",
        "\n",
        "    axes[2].imshow(tissue_healthy)\n",
        "    axes[2].set_title(\"full healthy tissue\")\n",
        "\n",
        "    axes[3].imshow(slide_image)\n",
        "    axes[3].imshow(np.ma.masked_values(tumor_image, 0), \n",
        "                    cmap='viridis', vmin=0, vmax=1, alpha=0.8)\n",
        "    axes[3].set_title(\"full tumor on slide\")\n",
        "      \n",
        "  print('Time: %.2f min' % extraction_time)\n",
        "  print(\"===Patch Extraction Done!===\")\n",
        "  \n",
        "  return data_patches, data_masks, data_labels\n",
        "\n",
        "def extract_patches_from_slide_id(slide_id, level, max_patches=200, force_reload=False):\n",
        "  slide = open_slide(os.path.join(SLIDE_DIR, SLIDE_FILE.format(id=slide_id)))\n",
        "  tumor_mask = open_slide(os.path.join(SLIDE_DIR, TUMOR_FILE.format(id=slide_id)))\n",
        "  \n",
        "  data_dir = 'preprocessed'\n",
        "  data_dir_path = os.path.join(folder_root, data_dir)\n",
        "  \n",
        "  print(\"======Start Extracting Patch ID {} Level {}======\".format(slide_id, level))\n",
        "  start_time = time.time()\n",
        "  \n",
        "  if not os.path.exists(data_dir_path):\n",
        "    print(\"{} does not exist! Creating a directory...\".format(data_dir_path))\n",
        "    os.mkdir(data_dir_path)\n",
        "      \n",
        "  patch_path = os.path.join(data_dir_path, \"patch_{}_lvl_{}.npy\".format(slide_id, level))\n",
        "  mask_path = os.path.join(data_dir_path, \"mask_{}_lvl_{}.npy\".format(slide_id, level))\n",
        "  label_path = os.path.join(data_dir_path, \"labels_{}_lvl_{}.npy\".format(slide_id, level))\n",
        "  \n",
        "  if not os.path.exists(patch_path) or \\\n",
        "    not os.path.exists(mask_path) or \\\n",
        "    not os.path.exists(label_path) or \\\n",
        "    force_reload:\n",
        "    print(\"Preprocessing data...\")\n",
        "    data_patches, data_masks, data_labels = extract_patches(slide, tumor_mask, \n",
        "                                                            level, max_patches=max_patches)\n",
        "    \n",
        "    np.save(patch_path, data_patches)\n",
        "    print(\"Wrote to {}\".format(patch_path))\n",
        "    np.save(mask_path, data_masks)\n",
        "    print(\"Wrote to {}\".format(mask_path))\n",
        "    np.save(label_path, data_labels)\n",
        "    print(\"Wrote to {}\".format(label_path))\n",
        "  else:\n",
        "    print(\"Data already exists! Preload existing data...\")\n",
        "    data_patches = np.load(patch_path)\n",
        "    data_masks = np.load(mask_path)\n",
        "    data_labels = np.load(label_path)\n",
        "    print(\"Total tumors: {}\".format(data_labels.sum()))\n",
        "  \n",
        "  patch_ext_time = (time.time() - start_time)/60\n",
        "  print('Time: %.2f min' % patch_ext_time)\n",
        "  print(\"======Finish Extracting Patch ID {} Level {}======\".format(slide_id, level))\n",
        "      \n",
        "  return data_patches, data_masks, data_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj8ObP1otenl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sanity Check: check extracted patches\n",
        "\n",
        "#From left to right, we show slide, tumor mask and slide plus tumor mask. For the tumor mask on slide,\n",
        "#we show the centre with red square.\n",
        "#if there is no tumor at the center we label it 0\n",
        "#if there is tumor at the center we label it 1.\n",
        "\n",
        "def plot_sample_patches(patches, masks, N=4, patch_center=128, patch_size=299):\n",
        "  \"\"\"Plot sample patches\n",
        "  patches: the patches\n",
        "  masks: the masks\n",
        "  \"\"\"\n",
        "  rand_indices = []\n",
        "  rand_indices.extend(np.random.choice(np.where(labels == 0)[0], N//2, replace=False))\n",
        "  rand_indices.extend(np.random.choice(np.where(labels == 1)[0], N//2, replace=False))\n",
        "\n",
        "  fig = plt.figure(figsize=(15/4*N, 15/4*N))\n",
        "  gs = gridspec.GridSpec(N, 3)\n",
        "\n",
        "  for i in range(N):\n",
        "    idx = rand_indices[i]\n",
        "\n",
        "    # plotting the 128x128 center\n",
        "    offset = int((patch_size - patch_center)/2)\n",
        "\n",
        "    ax = fig.add_subplot(gs[i, 0])\n",
        "    ax.imshow(patches[idx])\n",
        "    ax.set_title(\"slide\")\n",
        "    ax.set_ylabel(\"Label: {}\".format(labels[idx]))\n",
        "\n",
        "    ax = fig.add_subplot(gs[i, 1])\n",
        "    ax.imshow(masks[idx])\n",
        "    ax.set_title(\"tumor mask\")\n",
        "\n",
        "    ax = fig.add_subplot(gs[i, 2])\n",
        "    ax.imshow(patches[idx])\n",
        "    ax.imshow(np.ma.masked_values(masks[idx], 0), \n",
        "              cmap='viridis', vmin=0, vmax=1, alpha=0.8)\n",
        "    rect = mp_patches.Rectangle(\n",
        "        (int((patch_size - patch_center)/2), int((patch_size - patch_center)/2)),\n",
        "        patch_center, patch_center, linewidth=2, edgecolor='r', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    ax.set_title(\"tumor mask on slide\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdJa6oN4Tp8n",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading and Splitting\n",
        "\n",
        "This loads the processed data done in the previous part, and split the data into\n",
        "3 sets: training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGAzvXJWORK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_slides(level_dir, train_ids, test_ids):\n",
        "  \"\"\"This method loads several preprocessed slide images, tumors and labels\n",
        "  within the same zoom level used to speed up for experimentations and \n",
        "  exploring models and evaluations\n",
        "\n",
        "  level_dir: the directory of the slide images at level x\n",
        "  train_ids: the list of slide ids for training data\n",
        "  test_ids: the list of slide ids for test data\n",
        "  \"\"\"\n",
        "  files = os.listdir(level_dir)\n",
        "\n",
        "  # map id to patch, mask, labels, record\n",
        "  all_files = { }\n",
        "\n",
        "  for f in files:\n",
        "    fn = f.split(\"_\")\n",
        "    dtype, slide_id = fn[0], fn[1]\n",
        "    data = np.load(os.path.join(level_dir, f))\n",
        "    \n",
        "    if slide_id in all_files:\n",
        "      slide_data = all_files[slide_id]\n",
        "      slide_data[dtype] = data\n",
        "    else:\n",
        "      all_files[slide_id] = {}\n",
        "      all_files[slide_id][dtype] = data\n",
        "\n",
        "  train_patches, train_masks, train_labels, train_slide_ids = [], [], [], []\n",
        "  test_patches, test_masks, test_labels, test_slide_ids = [], [], [], []\n",
        "\n",
        "  for slide_id in all_files.keys():\n",
        "    N = len(all_files[slide_id]['patch'])\n",
        "    assert N == len(all_files[slide_id]['mask'])\n",
        "    assert N == len(all_files[slide_id]['labels'])\n",
        "\n",
        "    if slide_id in train_ids:\n",
        "      train_patches.extend(all_files[slide_id]['patch'])\n",
        "      train_masks.extend(all_files[slide_id]['mask'])\n",
        "      train_labels.extend(all_files[slide_id]['labels'])\n",
        "      train_slide_ids.extend([slide_id]*N)\n",
        "    elif slide_id in test_ids:\n",
        "      test_patches.extend(all_files[slide_id]['patch'])\n",
        "      test_masks.extend(all_files[slide_id]['mask'])\n",
        "      test_labels.extend(all_files[slide_id]['labels'])\n",
        "      test_slide_ids.extend([slide_id]*N)\n",
        "\n",
        "  return (np.array(train_patches), np.array(train_masks), \n",
        "          np.array(train_labels), np.array(train_slide_ids),\n",
        "          np.array(test_patches), np.array(test_masks),\n",
        "          np.array(test_labels), np.array(test_slide_ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7M9HzOhp396",
        "colab_type": "text"
      },
      "source": [
        "# Experiment Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFTQ3jCWpbQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEVEL_DIR = \"/content/drive/My Drive/level_4\"\n",
        "SLIDE_DIR = \"/content/drive/My Drive/slides_copy\"\n",
        "SLIDE_FILE = \"Copy of tumor_{id}.tif\"\n",
        "TUMOR_FILE = \"Copy of tumor_{id}_mask.tif\"\n",
        "\n",
        "MODEL_TAG = \"lvl4-all\"\n",
        "MODEL_BASE = \"vgg\"\n",
        "LOAD_EXISTING_MODEL = False\n",
        "LEVEL = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kan-fP8KqUKJ",
        "colab_type": "text"
      },
      "source": [
        "# Load All the Saved Slides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOCuvLlUgcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "good_slides = ['016', '019', '023', '031', '057', '064', '075', \n",
        "               '078', '084']\n",
        "\n",
        "# generate random training and testing ids\n",
        "# num_test = 3\n",
        "# train_ids = np.random.choice(good_slides, len(good_slides) - num_test, replace=False)\n",
        "# test_ids = list(set(good_slides) - set(train_ids))\n",
        "# print(\"Train: {}, Test: {}\".format(train_ids, test_ids))\n",
        "\n",
        "#train_ids = ['016', '064', '031', '019', '078', '075']\n",
        "#test_ids = ['057', '084', '023']\n",
        "\n",
        "train_ids = ['016', '064', '031', '075','078', '084', '094', '096', '101']\n",
        "test_ids = ['001', '005', '091']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46cS57NTWy4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_patches, train_masks, train_labels, train_slide_ids,\n",
        "    test_patches, test_masks, test_labels, test_slide_ids) = \\\n",
        "    load_all_slides(LEVEL_DIR, train_ids, test_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBMom9RM_Faj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu9ZhZ3g_Fal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(np.array(train_patches), \n",
        "                                                  np.array(train_labels), \n",
        "                                                  test_size=0.33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iqptf9VtoYU",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yCQrNn-p-KH",
        "colab_type": "text"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTygsXeAFkQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(base='vgg'):\n",
        "    model = tf.keras.Sequential()\n",
        "    if base == 'vgg':\n",
        "      conv_base = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                                              include_top=False,\n",
        "                                              input_shape=(299, 299, 3))\n",
        "    elif base == \"inception\":\n",
        "      conv_base = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet',\n",
        "                                                                 include_top=False,\n",
        "                                                                 input_shape=(299, 299, 3))\n",
        "\n",
        "    conv_base.trainable = False\n",
        "    model.add(conv_base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSlZYAFq_Fas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d0vNlEg_Fau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create data generators\n",
        "train_generator = train_datagen.flow(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size=32, \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = test_datagen.flow(\n",
        "    X_val, \n",
        "    y_val, \n",
        "    batch_size=32, \n",
        "    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1nNCpPh8nuo",
        "colab_type": "text"
      },
      "source": [
        "## Reload from Existing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMrcpAcNbh_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the latest model if available\n",
        "def load_latest_checkpoint(model_tag):\n",
        "  \"\"\"Loads the 'best' latest model for that model tag if it exists.\n",
        "\n",
        "  model_tag: the model id\n",
        "  \"\"\"\n",
        "  try:\n",
        "    model_dir = os.path.join(folder_root, \"models\")\n",
        "    model_path = os.path.join(model_dir, 'model_{tag}.h5'.format(tag=model_tag))\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "      print(\"Loading model and weights\")\n",
        "      model = tf.keras.models.load_model(model_path)\n",
        "    \n",
        "      checkpoint_path = os.path.join(folder_root, \n",
        "                                    'checkpoints-{tag}'.format(tag=model_tag))\n",
        "      latest = tf.train.latest_checkpoint(checkpoint_path)\n",
        "\n",
        "      if latest != None:\n",
        "        print(\"Loading weights from\", latest)\n",
        "        model.load_weights(latest)\n",
        "        \n",
        "        history = None\n",
        "\n",
        "        history_dir = os.path.join(folder_root, 'history')\n",
        "        history_path = os.path.join(history_dir, \"model_{tag}.pkl\".format(tag=model_tag))\n",
        "\n",
        "        if os.path.exists(history_path):\n",
        "          with open(history_path, 'rb') as fp:\n",
        "            history = pickle.load(fp)\n",
        "\n",
        "        return model, history\n",
        "    else:\n",
        "      print(\"Checkpoint not found. Starting from scratch\")\n",
        "  except ValueError:\n",
        "      pass\n",
        "    \n",
        "  return None, None\n",
        "\n",
        "def load_latest_model(model_tag):\n",
        "  \"\"\"Loads the last model trained for that model_tag if it exists.\n",
        "\n",
        "  model_tag: the model id\n",
        "  \"\"\"\n",
        "  try:\n",
        "    model_dir = os.path.join(folder_root, \"models\")\n",
        "    model_path = os.path.join(model_dir, 'model_{tag}.h5'.format(tag=model_tag))\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "      print(\"Loading model and weights\")\n",
        "      model = tf.keras.models.load_model(model_path)\n",
        "      \n",
        "      history = None\n",
        "\n",
        "      history_dir = os.path.join(folder_root, 'history')\n",
        "      history_path = os.path.join(history_dir, \"model_{tag}.pkl\".format(tag=model_tag))\n",
        "\n",
        "      if os.path.exists(history_path):\n",
        "        with open(history_path, 'rb') as fp:\n",
        "          history = pickle.load(fp)\n",
        "\n",
        "      return model, history\n",
        "    else:\n",
        "      print(\"Checkpoint not found. Starting from scratch\")\n",
        "  except ValueError:\n",
        "      pass\n",
        "  \n",
        "  return None, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuI0TOOo_Fay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, train_data_gen, val_data_gen, epochs, model_tag):\n",
        "  \"\"\"Train a CNN model for slide patches and corresponding labels. This method\n",
        "  will perform checkpointings (by saving the best weights) and utilize early \n",
        "  stop mechanism to stop the training when the model doesn't improve. \n",
        "\n",
        "  model: a CNN model\n",
        "  epochs: number of epochs\n",
        "  model_tag: the model ID\n",
        "  \"\"\"\n",
        "  # time model run\n",
        "  start_time = time.time()/60\n",
        "\n",
        "  # checkpoints dir\n",
        "  checkpoints_dir = 'checkpoints-{tag}'.format(tag=model_tag)\n",
        "  checkpoints_dir_path = os.path.join(folder_root, checkpoints_dir)\n",
        "\n",
        "  if not os.path.exists(checkpoints_dir_path):\n",
        "    os.mkdir(checkpoints_dir_path)\n",
        "\n",
        "  # history dir\n",
        "  history_dir = 'history'.format(tag=model_tag)\n",
        "  history_dir_path = os.path.join(folder_root, history_dir)\n",
        "\n",
        "  if not os.path.exists(history_dir_path):\n",
        "    os.mkdir(history_dir_path)\n",
        "\n",
        "  # models dir\n",
        "  models_dir = 'models'\n",
        "  models_dir_path = os.path.join(folder_root, models_dir)\n",
        "\n",
        "  if not os.path.exists(models_dir_path):\n",
        "    os.mkdir(models_dir_path)\n",
        "\n",
        "  checkpoint_path = os.path.join(checkpoints_dir_path, 'cp-{epoch:08d}.ckpt')\n",
        "  print(\"Checkpoint path: {}\".format(checkpoint_path))\n",
        "\n",
        "  # save checkpoints\n",
        "  callbacks = [\n",
        "      tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
        "                                       min_delta=0.001,\n",
        "                                       patience=10,\n",
        "                                       verbose=1),\n",
        "      tf.keras.callbacks.ModelCheckpoint(\n",
        "          filepath=checkpoint_path,\n",
        "          # Path where to save the model\n",
        "          # The two parameters below mean that we will overwrite\n",
        "          # the current checkpoint if and only if\n",
        "          # the `val_loss` score has improved.\n",
        "          save_best_only=True,\n",
        "          save_weights_only=True,\n",
        "          monitor='val_loss',\n",
        "          verbose=1)\n",
        "  ]\n",
        "\n",
        "  history = model.fit_generator(\n",
        "      train_data_gen,\n",
        "      epochs=epochs,\n",
        "      validation_data=val_data_gen,\n",
        "      callbacks=callbacks)\n",
        "\n",
        "  # save model to drive\n",
        "  model_filename = \"model_{tag}.h5\".format(tag=model_tag)\n",
        "  model_path = os.path.join(models_dir_path, model_filename)\n",
        "  \n",
        "  print(\"Saved model to: {}\".format(model_path))\n",
        "  model.save(model_path)\n",
        "\n",
        "  history_path = os.path.join(history_dir_path, 'model_{tag}.pkl'.format(tag=model_tag))\n",
        "  with open(history_path, \"wb\") as fp:\n",
        "      pickle.dump(history.history, fp)\n",
        "\n",
        "  train_time = time.time()/60 - start_time\n",
        "  print('Time: %.2f min' % train_time)\n",
        "\n",
        "  return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oig2uAL0E-vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model_history(history):\n",
        "  acc = history['acc']\n",
        "  val_acc = history['val_acc']\n",
        "  loss = history['loss']\n",
        "  val_loss = history['val_loss']\n",
        "\n",
        "  epochs = range(1, len(acc)+1)\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA_R_QwAqC5L",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQs53dWc8hD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, history = None, None\n",
        "\n",
        "if LOAD_EXISTING_MODEL:\n",
        "  model, history = load_latest_checkpoint(model_tag=MODEL_TAG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M6ECdLDe8Ubf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5e0e859-da67-4033-8e86-f914b1612d09"
      },
      "source": [
        "if not LOAD_EXISTING_MODEL or model is None:\n",
        "  model = create_model(base=MODEL_BASE)\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                optimizer='adam',\n",
        "                metrics=['acc'])\n",
        "  model, history = train_model(model, train_generator, val_generator, \n",
        "                              epochs=50, model_tag=MODEL_TAG)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Checkpoint path: /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-{epoch:08d}.ckpt\n",
            "WARNING:tensorflow:From <ipython-input-26-ffd91e0cbcf4>:59: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 26 steps, validate for 13 steps\n",
            "Epoch 1/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 2.9478 - acc: 0.5718\n",
            "Epoch 00001: val_loss improved from inf to 0.57883, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000001.ckpt\n",
            "26/26 [==============================] - 15s 591ms/step - loss: 2.9162 - acc: 0.5714 - val_loss: 0.5788 - val_acc: 0.7300\n",
            "Epoch 2/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.5821 - acc: 0.7410\n",
            "Epoch 00002: val_loss improved from 0.57883 to 0.49030, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000002.ckpt\n",
            "26/26 [==============================] - 6s 237ms/step - loss: 0.5690 - acc: 0.7488 - val_loss: 0.4903 - val_acc: 0.7150\n",
            "Epoch 3/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.4052 - acc: 0.7974\n",
            "Epoch 00003: val_loss improved from 0.49030 to 0.29456, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000003.ckpt\n",
            "26/26 [==============================] - 7s 274ms/step - loss: 0.4047 - acc: 0.7980 - val_loss: 0.2946 - val_acc: 0.9025\n",
            "Epoch 4/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.2808 - acc: 0.8859\n",
            "Epoch 00004: val_loss improved from 0.29456 to 0.25864, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000004.ckpt\n",
            "26/26 [==============================] - 6s 240ms/step - loss: 0.2771 - acc: 0.8879 - val_loss: 0.2586 - val_acc: 0.8950\n",
            "Epoch 5/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.2009 - acc: 0.9244\n",
            "Epoch 00005: val_loss improved from 0.25864 to 0.25531, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000005.ckpt\n",
            "26/26 [==============================] - 7s 271ms/step - loss: 0.1962 - acc: 0.9249 - val_loss: 0.2553 - val_acc: 0.8850\n",
            "Epoch 6/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.1909 - acc: 0.9218\n",
            "Epoch 00006: val_loss did not improve from 0.25531\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 0.1903 - acc: 0.9224 - val_loss: 0.2603 - val_acc: 0.9175\n",
            "Epoch 7/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.1706 - acc: 0.9410\n",
            "Epoch 00007: val_loss improved from 0.25531 to 0.23208, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000007.ckpt\n",
            "26/26 [==============================] - 6s 239ms/step - loss: 0.1705 - acc: 0.9397 - val_loss: 0.2321 - val_acc: 0.8900\n",
            "Epoch 8/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.1030 - acc: 0.9718\n",
            "Epoch 00008: val_loss improved from 0.23208 to 0.18973, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000008.ckpt\n",
            "26/26 [==============================] - 6s 227ms/step - loss: 0.1005 - acc: 0.9729 - val_loss: 0.1897 - val_acc: 0.9225\n",
            "Epoch 9/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0845 - acc: 0.9782\n",
            "Epoch 00009: val_loss did not improve from 0.18973\n",
            "26/26 [==============================] - 5s 200ms/step - loss: 0.0839 - acc: 0.9791 - val_loss: 0.2134 - val_acc: 0.9025\n",
            "Epoch 10/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0854 - acc: 0.9782\n",
            "Epoch 00010: val_loss improved from 0.18973 to 0.17532, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000010.ckpt\n",
            "26/26 [==============================] - 6s 240ms/step - loss: 0.0832 - acc: 0.9791 - val_loss: 0.1753 - val_acc: 0.9250\n",
            "Epoch 11/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0507 - acc: 0.9897\n",
            "Epoch 00011: val_loss improved from 0.17532 to 0.16706, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000011.ckpt\n",
            "26/26 [==============================] - 6s 241ms/step - loss: 0.0498 - acc: 0.9901 - val_loss: 0.1671 - val_acc: 0.9400\n",
            "Epoch 12/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0437 - acc: 0.9962\n",
            "Epoch 00012: val_loss improved from 0.16706 to 0.15769, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000012.ckpt\n",
            "26/26 [==============================] - 6s 241ms/step - loss: 0.0441 - acc: 0.9963 - val_loss: 0.1577 - val_acc: 0.9350\n",
            "Epoch 13/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0503 - acc: 0.9910\n",
            "Epoch 00013: val_loss did not improve from 0.15769\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0495 - acc: 0.9914 - val_loss: 0.2400 - val_acc: 0.9000\n",
            "Epoch 14/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0480 - acc: 0.9885\n",
            "Epoch 00014: val_loss did not improve from 0.15769\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0475 - acc: 0.9889 - val_loss: 0.2179 - val_acc: 0.9075\n",
            "Epoch 15/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0442 - acc: 0.9897\n",
            "Epoch 00015: val_loss did not improve from 0.15769\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0435 - acc: 0.9901 - val_loss: 0.1585 - val_acc: 0.9450\n",
            "Epoch 16/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0246 - acc: 1.0000\n",
            "Epoch 00016: val_loss did not improve from 0.15769\n",
            "26/26 [==============================] - 5s 200ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.1655 - val_acc: 0.9350\n",
            "Epoch 17/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0252 - acc: 0.9949\n",
            "Epoch 00017: val_loss improved from 0.15769 to 0.15678, saving model to /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000017.ckpt\n",
            "26/26 [==============================] - 6s 224ms/step - loss: 0.0256 - acc: 0.9951 - val_loss: 0.1568 - val_acc: 0.9400\n",
            "Epoch 18/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0279 - acc: 0.9974\n",
            "Epoch 00018: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0273 - acc: 0.9975 - val_loss: 0.1621 - val_acc: 0.9350\n",
            "Epoch 19/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0150 - acc: 1.0000\n",
            "Epoch 00019: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.9400\n",
            "Epoch 20/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0122 - acc: 1.0000\n",
            "Epoch 00020: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.9425\n",
            "Epoch 21/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0128 - acc: 1.0000\n",
            "Epoch 00021: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 202ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9425\n",
            "Epoch 22/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0109 - acc: 0.9974\n",
            "Epoch 00022: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0114 - acc: 0.9975 - val_loss: 0.1716 - val_acc: 0.9400\n",
            "Epoch 23/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0112 - acc: 0.9987\n",
            "Epoch 00023: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 200ms/step - loss: 0.0122 - acc: 0.9988 - val_loss: 0.1685 - val_acc: 0.9375\n",
            "Epoch 24/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0106 - acc: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0113 - acc: 0.9988 - val_loss: 0.1704 - val_acc: 0.9425\n",
            "Epoch 25/50\n",
            "25/26 [===========================>..] - ETA: 0s - loss: 0.0116 - acc: 1.0000\n",
            "Epoch 00025: val_loss did not improve from 0.15678\n",
            "26/26 [==============================] - 5s 201ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 0.9400\n",
            "Epoch 00025: early stopping\n",
            "Saved model to: /content/drive/My Drive/4995-final/models/model_lvl4-all.h5\n",
            "Time: 2.60 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvFsLoiLoDcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "66d94be0-05a1-4e10-8b91-a02ec5fd917c"
      },
      "source": [
        "model, history = load_latest_checkpoint(MODEL_TAG)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model and weights\n",
            "Loading weights from /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000017.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXDkedksMM_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "b62843b5-d716-4da5-8f02-fa2fe155ba52"
      },
      "source": [
        "plot_model_history(history)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGYUKCLiMTE/wdBg4K9BzvWswAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNckPdv6uxEs",
        "colab_type": "text"
      },
      "source": [
        "## Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adhtVTo6ghxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simple heatmap using the same image\n",
        "# split regions into 299x299, predict if center is tumor --> color the region with yellow\n",
        "def extract_test_data(slide, tumor_mask, lvl, patch_center=128, patch_size=299):\n",
        "  \"\"\"Extract the whole test patches from a slide at a level\n",
        "\n",
        "  slide: the slide for image\n",
        "  tumor_mask: the slide for tumor\n",
        "  lvl: the zoom level\n",
        "  patch_center: the patch center and center's pixel size\n",
        "  patch_size: the patch size\n",
        "  \"\"\"\n",
        "  print(\"===Start Extracting patches for Testing..===\")\n",
        "  start_time = time.time() / 60\n",
        "  dim = get_dim_from_slide(slide, lvl)\n",
        "\n",
        "  test_coords = []\n",
        "  test_patches = []\n",
        "  true_labels = []\n",
        "\n",
        "  count = 0\n",
        "  \n",
        "  for y in range(0, slide.level_dimensions[lvl][1], patch_center):\n",
        "    for x in range(0, slide.level_dimensions[lvl][0], patch_center):\n",
        "        # extract slide image by patch_size x patch_size centered at patch_center x patch_center size\n",
        "        slide_patch = read_slide(\n",
        "            slide, \n",
        "            x=(x + int(round(patch_center / 2)) - int(round(patch_size/2)))*dim, \n",
        "            y=(y + int(round(patch_center / 2)) - int(round(patch_size/2)))*dim,\n",
        "            level=lvl, \n",
        "            width=patch_size, \n",
        "            height=patch_size\n",
        "        )\n",
        "        \n",
        "        # extract tumor by patch_size x patch_size centered at patch_center x patch_center size\n",
        "        tumor_patch = read_slide(\n",
        "            tumor_mask, \n",
        "            x=(x + int(round(patch_center / 2)) - int(round(patch_size/2)))*dim, \n",
        "            y=(y + int(round(patch_center / 2)) - int(round(patch_size/2)))*dim,\n",
        "            level=lvl, \n",
        "            width=patch_size, \n",
        "            height=patch_size\n",
        "        )\n",
        "        # tumor patch just use one channel\n",
        "        tumor_patch = tumor_patch[:, :, 0]\n",
        "        \n",
        "        # check if it's a tissue pixels\n",
        "        tissue_pixels = find_tissue_pixels(slide_patch)\n",
        "        percent_tissue = len(tissue_pixels) / float(slide_patch.shape[0] * slide_patch.shape[0]) * 100\n",
        "        \n",
        "        if percent_tissue > 10:\n",
        "            test_coords.append((y, x))\n",
        "          \n",
        "            test_patches.append(slide_patch)\n",
        "            label = is_patch_tumor(tumor_patch, patch_center)\n",
        "            true_labels.append(int(label))\n",
        "\n",
        "            count += 1\n",
        "\n",
        "  test_coords = np.array(test_coords)\n",
        "  test_patches = np.array(test_patches)\n",
        "  true_labels = np.array(true_labels)\n",
        "\n",
        "  patch_ext_time = time.time()/60 - start_time\n",
        "\n",
        "  print(\"Extracted {} patches\".format(len(true_labels)))\n",
        "  print('Time: %.2f min' % patch_ext_time)\n",
        "  print(\"===Finsihed Extracting patches for Testing..===\")\n",
        "\n",
        "  return test_coords, test_patches, true_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7joV4xUuwTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_test_data(model, test_datagen, test_patches, true_labels):\n",
        "  test_generator = test_datagen.flow(\n",
        "    test_patches, \n",
        "    true_labels,\n",
        "    batch_size=32, \n",
        "    shuffle=False\n",
        "  )\n",
        "  \n",
        "  # predict test_patches\n",
        "  pred_labels = model.predict(test_generator)\n",
        "  pred_labels = pred_labels.ravel()\n",
        "\n",
        "  return pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNAxQJdGtkXx",
        "colab_type": "text"
      },
      "source": [
        "# Testing and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVGBIh3uu0Ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_prediction(true_labels, pred_labels):\n",
        "  # calculate roc, auc score and average precision on predicted probabilities\n",
        "  roc_auc = metrics.roc_auc_score(true_labels == 1, pred_labels)\n",
        "  avg_precision = metrics.average_precision_score(true_labels == 1, pred_labels)\n",
        "\n",
        "  # calculate f1, recall, and precision scores on the predicted labels (0 or 1)\n",
        "  precision = metrics.precision_score(true_labels == 1, pred_labels > 0.5)\n",
        "  recall = metrics.recall_score(true_labels == 1, pred_labels > 0.5)\n",
        "  f1 = metrics.f1_score(true_labels == 1, pred_labels > 0.5)\n",
        "\n",
        "  print(\"===Evaluation Metrics===\")\n",
        "  print('Precision score: %.3f' % precision)\n",
        "  print('Recall score: %.3f' % recall)\n",
        "  print('F1 score: %.3f' % f1)\n",
        "  print('ROC AUC score: %.3f' % roc_auc)\n",
        "  print('Average precision score: %.3f' % avg_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVdtoFuOveMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_prob_heatmap(pred_labels, slide, tumor_mask, lvl, coords, patch_center=128):\n",
        "  \"\"\"Plot the probability heatmap on the slide\n",
        "\n",
        "  pred_labels: the predicted probability\n",
        "  slide: the cell tissue slide\n",
        "  tumor_mask: the tumor mask slide\n",
        "  lvl: the zoom level\n",
        "  coords: the coordinates of the cells\n",
        "  patch_center: the patch center\n",
        "  \"\"\"\n",
        "  slide_image = read_slide(\n",
        "      slide,\n",
        "      x=0, \n",
        "      y=0, \n",
        "      level=lvl,\n",
        "      width=slide.level_dimensions[lvl][0],\n",
        "      height=slide.level_dimensions[lvl][1]\n",
        "  )\n",
        "\n",
        "  slide_tumor = read_slide(\n",
        "      tumor_mask,\n",
        "      x=0, \n",
        "      y=0, \n",
        "      level=lvl,\n",
        "      width=slide.level_dimensions[lvl][0],\n",
        "      height=slide.level_dimensions[lvl][1]\n",
        "  )\n",
        "  slide_tumor = slide_tumor[:,:,0]\n",
        "\n",
        "  # Src: https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_transparency_blend.html\n",
        "  hm_overlay = np.zeros(\n",
        "      (slide.level_dimensions[lvl][1], slide.level_dimensions[lvl][0])\n",
        "  )\n",
        "  for idx in range(len(coords)):\n",
        "    y, x = coords[idx]\n",
        "    hm_overlay[y:y+patch_center, x:x+patch_center] = pred_labels[idx]\n",
        "\n",
        "  # First we'll plot these blobs using only ``imshow``.\n",
        "  vmax = np.abs(hm_overlay).max()\n",
        "  vmin = 0\n",
        "  cmap = plt.cm.inferno\n",
        "\n",
        "  # Normalize the colors b/w 0 and 1, we'll then pass an MxNx4 array to imshow\n",
        "  colors = Normalize(vmin, vmax, clip=True)(hm_overlay)\n",
        "  colors = cmap(colors)\n",
        "\n",
        "  # 1 being opaque, 0 being transparent\n",
        "  # Now set the alpha channel to the one we created above\n",
        "  colors[..., -1] = hm_overlay/np.max(hm_overlay)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(15, 15))\n",
        "  axes[0].imshow(slide_image)\n",
        "  axes[0].imshow(np.ma.masked_values(slide_tumor, 0), \n",
        "                 cmap=cmap, vmin=0, vmax=1, alpha=0.8)\n",
        "\n",
        "  axes[1].imshow(slide_image)\n",
        "  axes[1].imshow(colors, vmin=vmin, vmax=vmax, cmap=cmap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juNQho4Lpt-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1705e5a4-bb3b-4364-ad53-d340587009d6"
      },
      "source": [
        "test_ids"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001', '005', '091']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jozwCtUwxMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model_on_slide(model, slide_id):\n",
        "  slide_path = os.path.join(SLIDE_DIR, TUMOR_FILE.format(\n",
        "                              id=slide_id\n",
        "                          ))\n",
        "\n",
        "  tumor_path = os.path.join(SLIDE_DIR, TUMOR_FILE.format(\n",
        "                                id=slide_id\n",
        "                            ))\n",
        "\n",
        "  slide_image = open_slide(slide_path)\n",
        "  slide_tumor = open_slide(tumor_path)\n",
        "\n",
        "  test_coords, test_patches, true_labels = extract_test_data(slide_image, \n",
        "                                                             slide_tumor, \n",
        "                                                             LEVEL, \n",
        "                                                             patch_center=128, \n",
        "                                                             patch_size=299)\n",
        "   \n",
        "  pred_labels = predict_test_data(model, test_datagen, test_patches, true_labels)\n",
        "  \n",
        "  evaluate_prediction(true_labels, pred_labels)\n",
        "  plot_prob_heatmap(pred_labels, slide_image, slide_tumor, LEVEL, test_coords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azxkiqElxU65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "95faae73-f51c-4088-cb68-6d4ccb969e1a"
      },
      "source": [
        "model, history = load_latest_checkpoint(MODEL_TAG)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model and weights\n",
            "Loading weights from /content/drive/My Drive/4995-final/checkpoints-lvl4-all/cp-00000017.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLKWwhYMxLHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39a5aab4-7de3-4a38-9a0a-c57a2c211502"
      },
      "source": [
        "evaluate_model_on_slide(model, test_ids[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===Start Extracting patches for Testing..===\n",
            "Extracted 5184 patches\n",
            "Time: 2.95 min\n",
            "===Finsihed Extracting patches for Testing..===\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===Evaluation Metrics===\n",
            "Precision score: 0.000\n",
            "Recall score: 0.000\n",
            "F1 score: 0.000\n",
            "ROC AUC score: 0.273\n",
            "Average precision score: 0.128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2sAAANSCAYAAAD7wFb1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHj5zBBtxBO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "753c8685-0f21-45e5-bc1b-62f36e52ff2a"
      },
      "source": [
        "evaluate_model_on_slide(model, test_ids[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===Start Extracting patches for Testing..===\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H62t5aXBxHeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_model_on_slide(model, test_ids[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNXEZYX68eAY",
        "colab": {}
      },
      "source": [
        "# window_size, stride"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}